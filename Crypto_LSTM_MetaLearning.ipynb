{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanketghosh19/Crypto_Price_Prediction/blob/main/Crypto_LSTM_MetaLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4WQ4l_Bu-e6G",
        "outputId": "a9de35d3-3def-4d33-e610-0ce52e1b39a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow numpy pandas matplotlib scikit-learn9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHsTtxDmtx-E",
        "outputId": "13755b37-95fd-46cb-cc28-33ee58b23cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "\n",
        "# Load Excel file\n",
        "file_path = '/content/drive/MyDrive/Output.xlsx'\n",
        "data = pd.read_excel(file_path, sheet_name=None)\n",
        "\n",
        "# Combine data for all coins\n",
        "features = ['price', 'volume', 'market_cap']\n",
        "data_cleaned = {}\n",
        "\n",
        "# Clean and scale data\n",
        "for coin, df in data.items():\n",
        "    df_selected = df[features].dropna()  # Drop rows with NaN values\n",
        "    if not df_selected.empty:\n",
        "        scaler = MinMaxScaler()\n",
        "        df_scaled = pd.DataFrame(scaler.fit_transform(df_selected), columns=features)\n",
        "        data_cleaned[coin] = df_scaled\n",
        "\n",
        "print(f\"Number of coins with valid data: {len(data_cleaned)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHQ2cWXD-ira",
        "outputId": "d70dd6ce-ab9a-496c-f0cd-ff3c1d7b9243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of coins with valid data: 719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create sequences\n",
        "def create_sequences(data, target_column, sequence_length=5):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(data.iloc[i:i + sequence_length].values)\n",
        "        y.append(data.iloc[i + sequence_length, target_column])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Select one coin's data for demonstration\n",
        "example_coin_data = data_cleaned[list(data_cleaned.keys())[0]]\n",
        "target_column_index = example_coin_data.columns.get_loc('price')\n",
        "\n",
        "# Create sequences\n",
        "sequence_length = 5\n",
        "X, y = create_sequences(example_coin_data, target_column=target_column_index, sequence_length=sequence_length)\n",
        "\n",
        "print(\"Input shape:\", X.shape)\n",
        "print(\"Output shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UdtApMI_a5D",
        "outputId": "793484f9-96d0-46e7-cf64-dd0051c48c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (23, 5, 3)\n",
            "Output shape: (23,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Build LSTM model\n",
        "def build_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(1))  # Predict next day's price\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Model input shape: (sequence_length, num_features)\n",
        "input_shape = (sequence_length, X.shape[2])\n",
        "model = build_lstm_model(input_shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "2HG0tU_l_fIy",
        "outputId": "66f57f49-46d2-4e2d-b054-6bf8491128d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m10,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,851\u001b[0m (42.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,851</span> (42.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,851\u001b[0m (42.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,851</span> (42.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing\n",
        "split = int(0.8 * len(X))  # 80% for training, 20% for testing\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qXl2TsJB_h1N",
        "outputId": "99832125-84cb-4f5d-81a2-205fe2a66ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 463ms/step - loss: 0.0499 - val_loss: 0.7767\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0413 - val_loss: 0.7324\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0401 - val_loss: 0.6908\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0353 - val_loss: 0.6499\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0306 - val_loss: 0.6088\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0287 - val_loss: 0.5685\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0263 - val_loss: 0.5304\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0227 - val_loss: 0.4935\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0204 - val_loss: 0.4570\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0185 - val_loss: 0.4230\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0149 - val_loss: 0.3909\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0147 - val_loss: 0.3586\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0140 - val_loss: 0.3286\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0131 - val_loss: 0.3021\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0123 - val_loss: 0.2791\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0112 - val_loss: 0.2578\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0122 - val_loss: 0.2384\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0118 - val_loss: 0.2237\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0123 - val_loss: 0.2138\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0115 - val_loss: 0.2117\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0115 - val_loss: 0.2134\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0125 - val_loss: 0.2151\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0117 - val_loss: 0.2194\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0118 - val_loss: 0.2276\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0116 - val_loss: 0.2381\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0114 - val_loss: 0.2483\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0108 - val_loss: 0.2539\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0105 - val_loss: 0.2584\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0108 - val_loss: 0.2635\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0108 - val_loss: 0.2639\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0114 - val_loss: 0.2623\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0105 - val_loss: 0.2600\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0101 - val_loss: 0.2584\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0112 - val_loss: 0.2587\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0108 - val_loss: 0.2577\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0111 - val_loss: 0.2555\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0101 - val_loss: 0.2519\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0109 - val_loss: 0.2470\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0109 - val_loss: 0.2442\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0108 - val_loss: 0.2417\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0107 - val_loss: 0.2382\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0107 - val_loss: 0.2352\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0096 - val_loss: 0.2368\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0106 - val_loss: 0.2429\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0105 - val_loss: 0.2475\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0101 - val_loss: 0.2520\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0106 - val_loss: 0.2562\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0107 - val_loss: 0.2569\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0103 - val_loss: 0.2577\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0105 - val_loss: 0.2571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Plot actual vs predicted prices\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test, label='Actual Price')\n",
        "plt.plot(y_pred, label='Predicted Price')\n",
        "plt.legend()\n",
        "plt.title(\"Actual vs Predicted Price\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "aVo-Yx_J_mz7",
        "outputId": "d0e75f4f-c7a9-4087-a6b5-8d633ddbc96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune for a new coin\n",
        "new_coin_data = data_cleaned[list(data_cleaned.keys())[1]]\n",
        "X_new, y_new = create_sequences(new_coin_data, target_column=target_column_index, sequence_length=sequence_length)\n",
        "\n",
        "# Fine-tune the model\n",
        "model.fit(X_new, y_new, epochs=10, batch_size=16)\n",
        "\n",
        "# Predict future prices\n",
        "future_predictions = model.predict(X_new[-3:])\n",
        "print(\"Predicted prices for next 3 days:\", future_predictions.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3Ee1KVP_p8B",
        "outputId": "91a732b9-e48b-48ba-fefd-1a678d7a0d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0106\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0105\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0104\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0103\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0103\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0102\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0101\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0100\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0099\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0098\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "Predicted prices for next 3 days: [0.1404792  0.16554335 0.19129935]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for coin, df in data_cleaned.items():\n",
        "    X_coin, y_coin = create_sequences(df, target_column=target_column_index, sequence_length=sequence_length)\n",
        "\n",
        "    # Check if enough data for training\n",
        "    if len(X_coin) > 0 and len(y_coin) > 0: #Checks if X_coin and y_coin are not empty\n",
        "        split = int(0.8 * len(X_coin))\n",
        "        X_train, X_test = X_coin[:split], X_coin[split:]\n",
        "        y_train, y_test = y_coin[:split], y_coin[split:]\n",
        "\n",
        "        # Train a model for each coin\n",
        "        model = build_lstm_model(input_shape)\n",
        "        model.fit(X_train, y_train, epochs=30, verbose=0)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Store the results\n",
        "        results[coin] = {\"y_test\": y_test, \"y_pred\": y_pred}\n",
        "    else:\n",
        "        print(f\"Skipping {coin} due to insufficient data.\")\n",
        "\n",
        "# Example output\n",
        "print(\"Predicted vs Actual for one coin:\")\n",
        "coin_name = list(results.keys())[0] # Get the first available coin after filtering\n",
        "print(\"Actual:\", results[coin_name][\"y_test\"][:5])\n",
        "print(\"Predicted:\", results[coin_name][\"y_pred\"][:5].flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRtdoAEEARrU",
        "outputId": "633f79b8-2655-4db9-962f-6e9ffc7d8fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c27ade148b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c27adbb3250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "Skipping alchemistai due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "Skipping bananaforscale2 due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "Skipping biaoonsol due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "Skipping brettmemecoin due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step\n",
            "Skipping dogc due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "Skipping fxn due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "Skipping hoppymeme due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "Skipping janrotherat due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "Skipping kappy due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "Skipping lambosforvirgins due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "Skipping legend due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
            "Skipping lifedog due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "Skipping limbo due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "Skipping lola3 due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "Skipping long4 due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "Skipping lunabyvirtuals due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "Skipping max2 due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "Skipping mindzero due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "Skipping moe4 due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "Skipping nothing4 due to insufficient data.\n",
            "Skipping novaonmars due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "Skipping nutcoinmeme due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "Skipping purplepepe due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "Skipping sadant due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "Skipping salvatormundi due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "Skipping size due to insufficient data.\n",
            "Skipping skainet due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "Skipping splashdog due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "Skipping theanthropicorder due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "Skipping thelokiecabal due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "Skipping vitai due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "Skipping would due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "Skipping zenith3 due to insufficient data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
            "Predicted vs Actual for one coin:\n",
            "Actual: [0.85403185 0.92059318 0.74865062 0.95675956 1.        ]\n",
            "Predicted: [0.25322136 0.30750367 0.36815462 0.40533343 0.4613284 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict future prices for any coin\n",
        "def predict_future_prices(coin_name, days_to_predict, model, data_cleaned, sequence_length=5):\n",
        "    \"\"\"\n",
        "    Predict future prices for a specified coin and period.\n",
        "\n",
        "    Parameters:\n",
        "        coin_name (str): Name of the meme coin.\n",
        "        days_to_predict (int): Number of future days to predict.\n",
        "        model (tf.keras.Model): Trained LSTM model.\n",
        "        data_cleaned (dict): Dictionary containing scaled data of all coins.\n",
        "        sequence_length (int): Number of time steps for input sequence.\n",
        "\n",
        "    Returns:\n",
        "        list: Predicted prices for the next 'days_to_predict' days.\n",
        "    \"\"\"\n",
        "    if coin_name not in data_cleaned:\n",
        "        print(f\"Coin '{coin_name}' not found in the dataset!\")\n",
        "        return []\n",
        "\n",
        "    # Retrieve the coin's scaled data\n",
        "    coin_data = data_cleaned[coin_name]\n",
        "    input_sequence = coin_data[-sequence_length:].values  # Take the last 'sequence_length' rows\n",
        "    input_sequence = input_sequence.reshape(1, sequence_length, -1)  # Reshape for LSTM input\n",
        "\n",
        "    predictions = []\n",
        "    for _ in range(days_to_predict):\n",
        "        # Predict next day's price\n",
        "        predicted_price = model.predict(input_sequence, verbose=0)[0][0]\n",
        "        predictions.append(predicted_price)\n",
        "\n",
        "        # Update input sequence: Append prediction and remove the oldest step\n",
        "        new_step = input_sequence[0, -1, :].copy()\n",
        "        new_step[0] = predicted_price  # Update the 'price' feature\n",
        "        input_sequence = np.append(input_sequence[:, 1:, :], [[new_step]], axis=1)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage\n",
        "coin_name = input(\"Enter the coin name (e.g., 1GUY): \")\n",
        "days_to_predict = int(input(\"Enter the number of days to predict: \"))\n",
        "\n",
        "# Build and train the model (ensure model is trained beforehand)\n",
        "model = build_lstm_model(input_shape)\n",
        "model.fit(X_train, y_train, epochs=30, verbose=0)\n",
        "\n",
        "# Predict future prices\n",
        "future_prices = predict_future_prices(coin_name, days_to_predict, model, data_cleaned)\n",
        "print(f\"Predicted prices for the next {days_to_predict} days: {future_prices}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ABIrUHXIIvh",
        "outputId": "03b2d5b4-6ebf-40ab-9714-90c0f973d850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the coin name (e.g., 1GUY): 1guy\n",
            "Enter the number of days to predict: 3\n",
            "Predicted prices for the next 3 days: [0.5422202, 0.5188515, 0.4900408]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select features for training\n",
        "features = ['price', 'volume', 'market_cap', 'market_cap_rank', 'twitter_sentiments']\n",
        "\n",
        "# Clean and scale data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data_cleaned = {}\n",
        "scalers = {}\n",
        "\n",
        "for coin, df in data.items():\n",
        "    df_selected = df[features].dropna()  # Drop rows with missing values\n",
        "    if not df_selected.empty:\n",
        "        scaler = MinMaxScaler()\n",
        "        df_scaled = pd.DataFrame(scaler.fit_transform(df_selected), columns=features)\n",
        "        data_cleaned[coin] = df_scaled\n",
        "        scalers[coin] = scaler  # Save scalers for later use\n"
      ],
      "metadata": {
        "id": "0PxE2SauJfc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, target_column, sequence_length=5):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(data.iloc[i:i + sequence_length].values)\n",
        "        y.append(data.iloc[i + sequence_length, target_column])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Prepare data for all coins\n",
        "sequence_length = 5\n",
        "all_X, all_y = [], []\n",
        "\n",
        "for coin, df in data_cleaned.items():\n",
        "    target_column_index = df.columns.get_loc('price')  # Predict 'price'\n",
        "    X, y = create_sequences(df, target_column=target_column_index, sequence_length=sequence_length)\n",
        "\n",
        "    # Check if X has the expected dimensions before appending\n",
        "    if X.ndim == 3:  # Ensure X has 3 dimensions\n",
        "        all_X.append(X)\n",
        "        all_y.append(y)\n",
        "    else:\n",
        "        print(f\"Skipping {coin} due to insufficient data for sequence creation.\")\n",
        "\n",
        "# Combine data from all coins\n",
        "# Check if all_X is not empty before stacking\n",
        "if all_X:\n",
        "    X_combined = np.vstack(all_X)\n",
        "    y_combined = np.hstack(all_y)\n",
        "    print(\"Combined data shape:\", X_combined.shape, y_combined.shape)\n",
        "else:\n",
        "    print(\"No coins had sufficient data to create sequences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAyB1ndmJ2TV",
        "outputId": "27e8b4f3-89f1-4b6a-cc59-d4605b683e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping alchemistai due to insufficient data for sequence creation.\n",
            "Skipping autism2 due to insufficient data for sequence creation.\n",
            "Skipping babygrok due to insufficient data for sequence creation.\n",
            "Skipping babyshironeko due to insufficient data for sequence creation.\n",
            "Skipping bananaforscale due to insufficient data for sequence creation.\n",
            "Skipping bananaforscale2 due to insufficient data for sequence creation.\n",
            "Skipping biaoonsol due to insufficient data for sequence creation.\n",
            "Skipping brettmemecoin due to insufficient data for sequence creation.\n",
            "Skipping chillgirl due to insufficient data for sequence creation.\n",
            "Skipping chudjak due to insufficient data for sequence creation.\n",
            "Skipping cryptoczar due to insufficient data for sequence creation.\n",
            "Skipping departmentofgovernmentefficienc due to insufficient data for sequence creation.\n",
            "Skipping dogc due to insufficient data for sequence creation.\n",
            "Skipping dogefather2 due to insufficient data for sequence creation.\n",
            "Skipping elonspetsnail due to insufficient data for sequence creation.\n",
            "Skipping fxn due to insufficient data for sequence creation.\n",
            "Skipping harold due to insufficient data for sequence creation.\n",
            "Skipping hoppymeme due to insufficient data for sequence creation.\n",
            "Skipping huahua due to insufficient data for sequence creation.\n",
            "Skipping janrotherat due to insufficient data for sequence creation.\n",
            "Skipping jorkin due to insufficient data for sequence creation.\n",
            "Skipping kappy due to insufficient data for sequence creation.\n",
            "Skipping kittekoin due to insufficient data for sequence creation.\n",
            "Skipping lambosforvirgins due to insufficient data for sequence creation.\n",
            "Skipping legend due to insufficient data for sequence creation.\n",
            "Skipping lifedog due to insufficient data for sequence creation.\n",
            "Skipping limbo due to insufficient data for sequence creation.\n",
            "Skipping lola3 due to insufficient data for sequence creation.\n",
            "Skipping long4 due to insufficient data for sequence creation.\n",
            "Skipping lunabyvirtuals due to insufficient data for sequence creation.\n",
            "Skipping mao3 due to insufficient data for sequence creation.\n",
            "Skipping max2 due to insufficient data for sequence creation.\n",
            "Skipping mindzero due to insufficient data for sequence creation.\n",
            "Skipping moe4 due to insufficient data for sequence creation.\n",
            "Skipping nothing4 due to insufficient data for sequence creation.\n",
            "Skipping novaonmars due to insufficient data for sequence creation.\n",
            "Skipping nutcoinmeme due to insufficient data for sequence creation.\n",
            "Skipping pigeontech due to insufficient data for sequence creation.\n",
            "Skipping rawr due to insufficient data for sequence creation.\n",
            "Skipping sadant due to insufficient data for sequence creation.\n",
            "Skipping sadhamster due to insufficient data for sequence creation.\n",
            "Skipping salvatormundi due to insufficient data for sequence creation.\n",
            "Skipping size due to insufficient data for sequence creation.\n",
            "Skipping skainet due to insufficient data for sequence creation.\n",
            "Skipping smokingchickenfish due to insufficient data for sequence creation.\n",
            "Skipping splashdog due to insufficient data for sequence creation.\n",
            "Skipping stardoge due to insufficient data for sequence creation.\n",
            "Skipping strategichubforinnovationinbloc due to insufficient data for sequence creation.\n",
            "Skipping theanthropicorder due to insufficient data for sequence creation.\n",
            "Skipping thelokiecabal due to insufficient data for sequence creation.\n",
            "Skipping tomocat due to insufficient data for sequence creation.\n",
            "Skipping universalbasiccompute due to insufficient data for sequence creation.\n",
            "Skipping vitai due to insufficient data for sequence creation.\n",
            "Skipping wolfofwallstreet due to insufficient data for sequence creation.\n",
            "Skipping would due to insufficient data for sequence creation.\n",
            "Skipping zenith3 due to insufficient data for sequence creation.\n",
            "Combined data shape: (8428, 5, 5) (8428,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Define the LSTM model\n",
        "def build_improved_lstm(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(Dropout(0.3))  # Prevent overfitting\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(1))  # Predict price\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Split data into training and testing\n",
        "split = int(0.8 * len(X_combined))\n",
        "X_train, X_test = X_combined[:split], X_combined[split:]\n",
        "y_train, y_test = y_combined[:split], y_combined[split:]\n",
        "\n",
        "# Train the model\n",
        "input_shape = (sequence_length, len(features))\n",
        "model = build_improved_lstm(input_shape)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDGv7_cqKGxh",
        "outputId": "856015ba-65ea-4d88-b2f6-40770d1de479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0656 - mae: 0.1910 - val_loss: 0.0319 - val_mae: 0.1320\n",
            "Epoch 2/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0305 - mae: 0.1246 - val_loss: 0.0277 - val_mae: 0.1103\n",
            "Epoch 3/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0286 - mae: 0.1185 - val_loss: 0.0273 - val_mae: 0.1073\n",
            "Epoch 4/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0291 - mae: 0.1182 - val_loss: 0.0268 - val_mae: 0.1100\n",
            "Epoch 5/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0281 - mae: 0.1162 - val_loss: 0.0269 - val_mae: 0.1126\n",
            "Epoch 6/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0287 - mae: 0.1163 - val_loss: 0.0275 - val_mae: 0.1144\n",
            "Epoch 7/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1146 - val_loss: 0.0279 - val_mae: 0.1058\n",
            "Epoch 8/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0280 - mae: 0.1141 - val_loss: 0.0269 - val_mae: 0.1129\n",
            "Epoch 9/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0268 - mae: 0.1129 - val_loss: 0.0276 - val_mae: 0.1054\n",
            "Epoch 10/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0254 - mae: 0.1118 - val_loss: 0.0272 - val_mae: 0.1181\n",
            "Epoch 11/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0269 - mae: 0.1158 - val_loss: 0.0271 - val_mae: 0.1060\n",
            "Epoch 12/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0277 - mae: 0.1149 - val_loss: 0.0270 - val_mae: 0.1138\n",
            "Epoch 13/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0282 - mae: 0.1150 - val_loss: 0.0264 - val_mae: 0.1096\n",
            "Epoch 14/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0276 - mae: 0.1139 - val_loss: 0.0272 - val_mae: 0.1092\n",
            "Epoch 15/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0277 - mae: 0.1155 - val_loss: 0.0267 - val_mae: 0.1048\n",
            "Epoch 16/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0255 - mae: 0.1103 - val_loss: 0.0268 - val_mae: 0.1090\n",
            "Epoch 17/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0260 - mae: 0.1116 - val_loss: 0.0262 - val_mae: 0.1077\n",
            "Epoch 18/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0257 - mae: 0.1099 - val_loss: 0.0269 - val_mae: 0.1132\n",
            "Epoch 19/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0252 - mae: 0.1101 - val_loss: 0.0266 - val_mae: 0.1075\n",
            "Epoch 20/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0274 - mae: 0.1145 - val_loss: 0.0264 - val_mae: 0.1059\n",
            "Epoch 21/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0257 - mae: 0.1104 - val_loss: 0.0267 - val_mae: 0.1042\n",
            "Epoch 22/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0265 - mae: 0.1127 - val_loss: 0.0263 - val_mae: 0.1103\n",
            "Epoch 23/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0267 - mae: 0.1115 - val_loss: 0.0264 - val_mae: 0.1045\n",
            "Epoch 24/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0254 - mae: 0.1100 - val_loss: 0.0264 - val_mae: 0.1075\n",
            "Epoch 25/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0270 - mae: 0.1135 - val_loss: 0.0259 - val_mae: 0.1049\n",
            "Epoch 26/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0252 - mae: 0.1106 - val_loss: 0.0263 - val_mae: 0.1066\n",
            "Epoch 27/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0251 - mae: 0.1086 - val_loss: 0.0261 - val_mae: 0.1063\n",
            "Epoch 28/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1120 - val_loss: 0.0273 - val_mae: 0.1058\n",
            "Epoch 29/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0262 - mae: 0.1117 - val_loss: 0.0262 - val_mae: 0.1081\n",
            "Epoch 30/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0254 - mae: 0.1091 - val_loss: 0.0260 - val_mae: 0.1105\n",
            "Epoch 31/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0261 - mae: 0.1114 - val_loss: 0.0260 - val_mae: 0.1043\n",
            "Epoch 32/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0257 - mae: 0.1109 - val_loss: 0.0260 - val_mae: 0.1078\n",
            "Epoch 33/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0268 - mae: 0.1131 - val_loss: 0.0257 - val_mae: 0.1059\n",
            "Epoch 34/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0243 - mae: 0.1081 - val_loss: 0.0257 - val_mae: 0.1043\n",
            "Epoch 35/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0248 - mae: 0.1103 - val_loss: 0.0255 - val_mae: 0.1059\n",
            "Epoch 36/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0251 - mae: 0.1103 - val_loss: 0.0257 - val_mae: 0.1033\n",
            "Epoch 37/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0249 - mae: 0.1094 - val_loss: 0.0261 - val_mae: 0.1088\n",
            "Epoch 38/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0236 - mae: 0.1069 - val_loss: 0.0259 - val_mae: 0.1024\n",
            "Epoch 39/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0252 - mae: 0.1091 - val_loss: 0.0253 - val_mae: 0.1063\n",
            "Epoch 40/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0244 - mae: 0.1080 - val_loss: 0.0257 - val_mae: 0.1084\n",
            "Epoch 41/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0248 - mae: 0.1084 - val_loss: 0.0255 - val_mae: 0.1077\n",
            "Epoch 42/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0246 - mae: 0.1083 - val_loss: 0.0259 - val_mae: 0.1083\n",
            "Epoch 43/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0255 - mae: 0.1103 - val_loss: 0.0251 - val_mae: 0.1039\n",
            "Epoch 44/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0245 - mae: 0.1087 - val_loss: 0.0256 - val_mae: 0.1042\n",
            "Epoch 45/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0241 - mae: 0.1080 - val_loss: 0.0250 - val_mae: 0.1026\n",
            "Epoch 46/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0242 - mae: 0.1085 - val_loss: 0.0249 - val_mae: 0.1056\n",
            "Epoch 47/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0239 - mae: 0.1076 - val_loss: 0.0251 - val_mae: 0.1053\n",
            "Epoch 48/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0241 - mae: 0.1072 - val_loss: 0.0248 - val_mae: 0.1026\n",
            "Epoch 49/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0243 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1059\n",
            "Epoch 50/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0250 - mae: 0.1096 - val_loss: 0.0250 - val_mae: 0.1015\n",
            "Epoch 51/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0247 - mae: 0.1082 - val_loss: 0.0246 - val_mae: 0.1001\n",
            "Epoch 52/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0232 - mae: 0.1046 - val_loss: 0.0247 - val_mae: 0.1060\n",
            "Epoch 53/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0244 - mae: 0.1099 - val_loss: 0.0246 - val_mae: 0.1022\n",
            "Epoch 54/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0242 - mae: 0.1079 - val_loss: 0.0246 - val_mae: 0.1007\n",
            "Epoch 55/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0238 - mae: 0.1067 - val_loss: 0.0250 - val_mae: 0.1022\n",
            "Epoch 56/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0237 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1006\n",
            "Epoch 57/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0265 - mae: 0.1114 - val_loss: 0.0248 - val_mae: 0.1024\n",
            "Epoch 58/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0228 - mae: 0.1044 - val_loss: 0.0253 - val_mae: 0.1110\n",
            "Epoch 59/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0243 - mae: 0.1080 - val_loss: 0.0246 - val_mae: 0.1007\n",
            "Epoch 60/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0243 - mae: 0.1080 - val_loss: 0.0257 - val_mae: 0.1072\n",
            "Epoch 61/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1124 - val_loss: 0.0250 - val_mae: 0.1065\n",
            "Epoch 62/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0255 - mae: 0.1109 - val_loss: 0.0245 - val_mae: 0.1002\n",
            "Epoch 63/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0241 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1024\n",
            "Epoch 64/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0237 - mae: 0.1071 - val_loss: 0.0247 - val_mae: 0.1024\n",
            "Epoch 65/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0243 - mae: 0.1080 - val_loss: 0.0246 - val_mae: 0.1032\n",
            "Epoch 66/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0238 - mae: 0.1059 - val_loss: 0.0249 - val_mae: 0.1056\n",
            "Epoch 67/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0240 - mae: 0.1068 - val_loss: 0.0243 - val_mae: 0.1039\n",
            "Epoch 68/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0223 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1032\n",
            "Epoch 69/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0232 - mae: 0.1058 - val_loss: 0.0246 - val_mae: 0.1020\n",
            "Epoch 70/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0231 - mae: 0.1052 - val_loss: 0.0243 - val_mae: 0.1005\n",
            "Epoch 71/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0237 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.0996\n",
            "Epoch 72/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0241 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1021\n",
            "Epoch 73/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0242 - mae: 0.1084 - val_loss: 0.0248 - val_mae: 0.1071\n",
            "Epoch 74/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0230 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1009\n",
            "Epoch 75/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0231 - mae: 0.1051 - val_loss: 0.0242 - val_mae: 0.1018\n",
            "Epoch 76/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0246 - mae: 0.1080 - val_loss: 0.0242 - val_mae: 0.1014\n",
            "Epoch 77/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0228 - mae: 0.1035 - val_loss: 0.0246 - val_mae: 0.1066\n",
            "Epoch 78/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0248 - mae: 0.1099 - val_loss: 0.0246 - val_mae: 0.1042\n",
            "Epoch 79/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0244 - mae: 0.1083 - val_loss: 0.0246 - val_mae: 0.1033\n",
            "Epoch 80/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0232 - mae: 0.1065 - val_loss: 0.0247 - val_mae: 0.1029\n",
            "Epoch 81/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0228 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1000\n",
            "Epoch 82/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0238 - mae: 0.1064 - val_loss: 0.0244 - val_mae: 0.1038\n",
            "Epoch 83/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0228 - mae: 0.1050 - val_loss: 0.0242 - val_mae: 0.1014\n",
            "Epoch 84/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0224 - mae: 0.1027 - val_loss: 0.0245 - val_mae: 0.1067\n",
            "Epoch 85/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0235 - mae: 0.1068 - val_loss: 0.0251 - val_mae: 0.0999\n",
            "Epoch 86/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0235 - mae: 0.1057 - val_loss: 0.0243 - val_mae: 0.1006\n",
            "Epoch 87/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.0233 - mae: 0.1059 - val_loss: 0.0244 - val_mae: 0.1018\n",
            "Epoch 88/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0231 - mae: 0.1054 - val_loss: 0.0250 - val_mae: 0.1000\n",
            "Epoch 89/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0235 - mae: 0.1057 - val_loss: 0.0244 - val_mae: 0.1044\n",
            "Epoch 90/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0225 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1053\n",
            "Epoch 91/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0220 - mae: 0.1028 - val_loss: 0.0247 - val_mae: 0.1066\n",
            "Epoch 92/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0236 - mae: 0.1079 - val_loss: 0.0243 - val_mae: 0.1011\n",
            "Epoch 93/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0227 - mae: 0.1050 - val_loss: 0.0245 - val_mae: 0.0996\n",
            "Epoch 94/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0222 - mae: 0.1024 - val_loss: 0.0242 - val_mae: 0.1032\n",
            "Epoch 95/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0229 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1017\n",
            "Epoch 96/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0220 - mae: 0.1031 - val_loss: 0.0245 - val_mae: 0.1036\n",
            "Epoch 97/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0231 - mae: 0.1059 - val_loss: 0.0242 - val_mae: 0.1016\n",
            "Epoch 98/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0225 - mae: 0.1027 - val_loss: 0.0245 - val_mae: 0.1031\n",
            "Epoch 99/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0225 - mae: 0.1040 - val_loss: 0.0250 - val_mae: 0.1006\n",
            "Epoch 100/100\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0233 - mae: 0.1062 - val_loss: 0.0249 - val_mae: 0.1046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_future_prices(coin_name, days_to_predict, model, data_cleaned, scalers, sequence_length=5):\n",
        "    scaler = scalers[coin_name]\n",
        "    coin_data = data_cleaned[coin_name]\n",
        "    input_sequence = coin_data[-sequence_length:].values.reshape(1, sequence_length, -1)\n",
        "\n",
        "    predictions = []\n",
        "    for _ in range(days_to_predict):\n",
        "        predicted_price = model.predict(input_sequence, verbose=0)[0][0]\n",
        "        predictions.append(predicted_price)\n",
        "\n",
        "        # Update input sequence with the predicted price\n",
        "        new_step = input_sequence[0, -1, :].copy()\n",
        "        new_step[0] = predicted_price  # Update 'price'\n",
        "        input_sequence = np.append(input_sequence[:, 1:, :], [[new_step]], axis=1)\n",
        "\n",
        "    # Inverse transform to original scale\n",
        "    predicted_prices = scaler.inverse_transform([[p, 0, 0, 0, 0] for p in predictions])[:, 0]\n",
        "    return predicted_prices\n",
        "\n",
        "# Predict prices for a specific coin\n",
        "coin_name = \"tema\"\n",
        "days_to_predict = 3\n",
        "future_prices = predict_future_prices(coin_name, days_to_predict, model, data_cleaned, scalers)\n",
        "\n",
        "print(f\"Predicted prices for the next {days_to_predict} days:\", future_prices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLjgOuxTdDTR",
        "outputId": "2b22b55d-c0bd-4ca1-db08-9b414abb77f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted prices for the next 3 days: [0.00418382 0.00397184 0.004177  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Evaluate model accuracy on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute R2 Score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "accuracy_percentage = r2 * 100\n",
        "\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"Accuracy: {accuracy_percentage:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyJagsdet1kB",
        "outputId": "b1a9767e-2850-477a-d549-33043895f363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "R² Score: 0.6954\n",
            "Accuracy: 69.54%\n"
          ]
        }
      ]
    }
  ]
}